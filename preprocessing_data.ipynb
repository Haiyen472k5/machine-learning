{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a64e043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge file \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# CẤU HÌNH (LOCAL)\n",
    "# =========================\n",
    "\n",
    "# ROOT dataset trên máy bạn\n",
    "DATA_ROOT = r\"C:\\Users\\haiye\\OneDrive\\Desktop\\Nam3_Ki1\\Machine_learning\\BTL\\mallorn-astronomical-classification-challenge\"\n",
    "\n",
    "# Thư mục output (tạo cùng thư mục notebook)\n",
    "OUT_ROOT = \"cleaned_data\"\n",
    "\n",
    "SPLITS = range(1, 21)\n",
    "\n",
    "REQUIRED_COLS = [\"object_id\", \"Time (MJD)\", \"Flux\", \"Flux_err\", \"Filter\"]\n",
    "VALID_FILTERS = {\"u\", \"g\", \"r\", \"i\", \"z\", \"y\"}\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "train_log = pd.read_csv(\"train_log.csv\")\n",
    "test_log = pd.read_csv(\"test_log.csv\")\n",
    "# =========================\n",
    "# HÀM CLEAN\n",
    "# =========================\n",
    "def clean_lightcurve_file(csv_path, is_test_set=False):\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"!!! Warning: Không tìm thấy file {csv_path}\")\n",
    "        return pd.DataFrame(), 0, 0\n",
    "\n",
    "    lc = pd.read_csv(csv_path)\n",
    "    n_before = len(lc)\n",
    "\n",
    "    original_ids = lc['object_id'].unique() if is_test_set else None\n",
    "\n",
    "    # ---- 1. Lọc cơ bản ----\n",
    "    mask = (\n",
    "        lc[REQUIRED_COLS].notna().all(axis=1) &\n",
    "        (lc[\"Flux_err\"] > 0) &\n",
    "        (lc[\"Flux_err\"] < 1e6) &\n",
    "        (lc[\"Filter\"].isin(VALID_FILTERS)) &\n",
    "        (lc[\"Flux\"].abs() <= 1e10)\n",
    "    )\n",
    "\n",
    "    lc_clean = lc[mask].copy()\n",
    "\n",
    "    # ---- 2. GỘP TRÙNG (Weighted Average) ----\n",
    "    lc_clean['w'] = 1.0 / (lc_clean['Flux_err'] ** 2)\n",
    "    lc_clean['flux_w'] = lc_clean['Flux'] * lc_clean['w']\n",
    "\n",
    "    group_cols = [\"object_id\", \"Time (MJD)\", \"Filter\"]\n",
    "\n",
    "    lc_grouped = (\n",
    "        lc_clean\n",
    "        .groupby(group_cols)[['flux_w', 'w']]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    lc_grouped['Flux'] = lc_grouped['flux_w'] / lc_grouped['w']\n",
    "    lc_grouped['Flux_err'] = 1.0 / np.sqrt(lc_grouped['w'])\n",
    "\n",
    "    lc_final = lc_grouped[REQUIRED_COLS].copy()\n",
    "\n",
    "    # ---- 3. CỨU HỘ TEST ----\n",
    "    if is_test_set:\n",
    "        remaining_ids = set(lc_final['object_id'].unique())\n",
    "        missing_ids = set(original_ids) - remaining_ids\n",
    "\n",
    "        if missing_ids:\n",
    "            print(f\"   ⚠️ CỨU {len(missing_ids)} ID bị mất trong TEST\")\n",
    "            rescue_df = lc[lc['object_id'].isin(missing_ids)].copy()\n",
    "            rescue_df['Flux'] = rescue_df['Flux'].fillna(0)\n",
    "            bad_err_mask = (rescue_df['Flux_err'].isna()) | (rescue_df['Flux_err'] <= 0)\n",
    "            rescue_df.loc[bad_err_mask, 'Flux_err'] = 100.0\n",
    "            \n",
    "            rescue_df = rescue_df[REQUIRED_COLS]\n",
    "\n",
    "            lc_final = pd.concat([lc_final, rescue_df], ignore_index=True)\n",
    "\n",
    "    # ---- 4. Sort ----\n",
    "    lc_final = lc_final.sort_values([\"object_id\", \"Time (MJD)\"])\n",
    "\n",
    "    n_after = len(lc_final)\n",
    "\n",
    "\n",
    "    return lc_final, n_before, n_after\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a23677",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extinction import fitzpatrick99\n",
    "\n",
    "def apply_extinction_correction(lc_df, metadata_df):\n",
    "    print(\"--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\")\n",
    "    \n",
    "    # 1. Định nghĩa bước sóng (như cũ)\n",
    "    WAVELENGTHS = {\n",
    "        \"u\": 3641.0, \"g\": 4704.0, \"r\": 6155.0,\n",
    "        \"i\": 7504.0, \"z\": 8695.0, \"y\": 10056.0,\n",
    "    }\n",
    "    \n",
    "    # 2. Merge Metadata\n",
    "    meta = metadata_df.copy()\n",
    "    \n",
    "    # Kiểm tra xem cột trong metadata là 'EBV' hay 'mwebv'\n",
    "    ebv_col = 'EBV' \n",
    "    if ebv_col not in meta.columns:\n",
    "        raise ValueError(\"Metadata thiếu cột 'EBV'\")\n",
    "\n",
    "    # Merge (chú ý chỉ lấy đúng cột cần)\n",
    "    lc_final = lc_df.merge(meta[['object_id', ebv_col]], on='object_id', how='left')\n",
    "    \n",
    "    # Fillna cho EBV nếu bị thiếu (mặc định là 0 - không sửa)\n",
    "    if lc_final[ebv_col].isna().any():\n",
    "        print(f\"Cảnh báo: Có {lc_final[ebv_col].isna().sum()} dòng thiếu EBV. Điền 0.\")\n",
    "        lc_final[ebv_col] = lc_final[ebv_col].fillna(0)\n",
    "\n",
    "    # 3. Tính toán Extinction (Vectorized - Không vòng lặp av)\n",
    "    # Lấy giá trị EBV và clip cho an toàn\n",
    "    ebv_values = np.clip(lc_final[ebv_col].values, 0, 2.0) # Clip 1.0 hơi gắt, 10.0 an toàn hơn cho vùng tối\n",
    "    high_ebv = (lc_final[ebv_col] > 2.0).sum()\n",
    "    if high_ebv > 0:\n",
    "        print(f\"   ⚠️ Warning: {high_ebv} points have EBV > 2.0 (clipped)\")\n",
    "        \n",
    "    # Tạo mảng A_lambda chứa giá trị dập tắt cho từng dòng\n",
    "    A_lambda = np.zeros(len(lc_final), dtype=float)\n",
    "    \n",
    "    # Tính hệ số cho từng filter (Nhanh hơn loop theo EBV)\n",
    "    # R_v = 3.1 (Milky Way average)\n",
    "    for filt, wave in WAVELENGTHS.items():\n",
    "        mask = (lc_final['Filter'] == filt)\n",
    "        if not mask.any(): continue\n",
    "        \n",
    "        # Tính A_lambda cho EBV=1.0 (Unit Extinction)\n",
    "        # fitzpatrick99(wave, a_v, r_v) -> a_v ở đây ta để 3.1 vì A_V = R_V * E(B-V)\n",
    "        # Khi E(B-V) = 1 thì A_V = 3.1\n",
    "        unit_ext = fitzpatrick99(np.array([wave]), 3.1, 3.1)[0]\n",
    "        \n",
    "        # Extinction thực tế = Unit_Ext * EBV thực tế\n",
    "        A_lambda[mask] = unit_ext * ebv_values[mask]\n",
    "\n",
    "    # 4. Áp dụng công thức hiệu chỉnh Flux\n",
    "    # Công thức: F_true = F_obs * 10^(0.4 * A_lambda)\n",
    "    # Bạn dùng 10**(A/2.5) chính là 10**(0.4*A) -> ĐÚNG\n",
    "    corr_factor = 10.0 ** (0.4 * A_lambda)\n",
    "    \n",
    "    lc_final['Flux'] = lc_final['Flux'] * corr_factor\n",
    "    lc_final['Flux_err'] = lc_final['Flux_err'] * corr_factor\n",
    "    \n",
    "    # 5. Dọn dẹp (Sửa lỗi inplace ở đây)\n",
    "    lc_final = lc_final.drop(columns=[ebv_col]) \n",
    "    \n",
    "    print(f\"--- HOÀN THÀNH (Đã sửa {len(lc_final)} điểm dữ liệu) ---\")\n",
    "    return lc_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12840772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_quality_filters(lc_df):\n",
    "    \"\"\"\n",
    "    Filter objects that are too poor for feature engineering\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Calculate SNR\n",
    "    lc_df['SNR'] = lc_df['Flux'] / lc_df['Flux_err']\n",
    "    \n",
    "    # 2. Per-object statistics\n",
    "    obj_stats = lc_df.groupby('object_id').agg({\n",
    "        'object_id': 'size',  # n_obs\n",
    "        'SNR': lambda x: (x > 3).sum(),  # n_detections\n",
    "        'Time (MJD)': lambda x: x.max() - x.min(),  # time_span\n",
    "        'Filter': 'nunique'  # n_filters\n",
    "    }).rename(columns={\n",
    "        'object_id': 'n_obs',\n",
    "        'SNR': 'n_det',\n",
    "        'Time (MJD)': 'time_span',\n",
    "        'Filter': 'n_filters'\n",
    "    })\n",
    "    \n",
    "    # 3. Apply filters (TRAIN only - keep all TEST)\n",
    "    valid_objects = obj_stats[\n",
    "        (obj_stats['n_obs'] >= 5) &      # Ít nhất 5 observations\n",
    "        (obj_stats['n_det'] >= 3) &      # Ít nhất 3 detections\n",
    "        (obj_stats['time_span'] >= 3) &  # Ít nhất 3 ngày coverage\n",
    "        (obj_stats['n_filters'] >= 1)    # Ít nhất 1 filter (loose)\n",
    "    ].index\n",
    "    \n",
    "    print(f\"   Quality filter: {len(valid_objects)}/{len(obj_stats)} objects pass\")\n",
    "    lc_df = lc_df.drop(columns=['SNR'])\n",
    "    \n",
    "    return lc_df[lc_df['object_id'].isin(valid_objects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6d9e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 1. LOADING METADATA (LOG FILES) =====\n",
      "✅ Loaded Train Log: 3043 objects\n",
      "✅ Loaded Test Log: 7135 objects\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_TRAIN_LOG = (\"train_log.csv\") \n",
    "PATH_TO_TEST_LOG = (\"test_log.csv\")\n",
    "\n",
    "print(\"===== 1. LOADING METADATA (LOG FILES) =====\")\n",
    "try:\n",
    "    meta_train_master = pd.read_csv(PATH_TO_TRAIN_LOG)\n",
    "    print(f\"✅ Loaded Train Log: {len(meta_train_master)} objects\")\n",
    "    \n",
    "    meta_test_master = pd.read_csv(PATH_TO_TEST_LOG)\n",
    "    print(f\"✅ Loaded Test Log: {len(meta_test_master)} objects\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"❌ Error: Không tìm thấy file log. Kiểm tra lại đường dẫn!\\n{e}\")\n",
    "    # Dừng chương trình nếu không có metadata (vì không khử bụi được)\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961f9363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 2. START PROCESSING SPLITS =====\n",
      "\n",
      "Processing Split_01...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 26313 điểm dữ liệu) ---\n",
      "   Quality filter: 155/155 objects pass\n",
      "   | TRAIN | Raw:   26324 -> Final:   26313 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 59212 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   59235 -> Final:   59212 | Saved.\n",
      "\n",
      "Processing Split_02...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 25603 điểm dữ liệu) ---\n",
      "   Quality filter: 170/170 objects pass\n",
      "   | TRAIN | Raw:   25609 -> Final:   25603 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 71221 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   71229 -> Final:   71221 | Saved.\n",
      "\n",
      "Processing Split_03...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 21671 điểm dữ liệu) ---\n",
      "   Quality filter: 138/138 objects pass\n",
      "   | TRAIN | Raw:   21676 -> Final:   21671 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 53743 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   53751 -> Final:   53743 | Saved.\n",
      "\n",
      "Processing Split_04...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 22886 điểm dữ liệu) ---\n",
      "   Quality filter: 145/145 objects pass\n",
      "   | TRAIN | Raw:   22898 -> Final:   22886 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 51358 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   51408 -> Final:   51358 | Saved.\n",
      "\n",
      "Processing Split_05...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 25919 điểm dữ liệu) ---\n",
      "   Quality filter: 165/165 objects pass\n",
      "   | TRAIN | Raw:   25934 -> Final:   25919 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 61137 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   61179 -> Final:   61137 | Saved.\n",
      "\n",
      "Processing Split_06...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 25673 điểm dữ liệu) ---\n",
      "   Quality filter: 155/155 objects pass\n",
      "   | TRAIN | Raw:   25684 -> Final:   25673 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 57599 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   57620 -> Final:   57599 | Saved.\n",
      "\n",
      "Processing Split_07...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 24167 điểm dữ liệu) ---\n",
      "   Quality filter: 165/165 objects pass\n",
      "   | TRAIN | Raw:   24473 -> Final:   24167 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 64197 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   65101 -> Final:   64197 | Saved.\n",
      "\n",
      "Processing Split_08...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 25565 điểm dữ liệu) ---\n",
      "   Quality filter: 162/162 objects pass\n",
      "   | TRAIN | Raw:   25571 -> Final:   25565 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 61451 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   61498 -> Final:   61451 | Saved.\n",
      "\n",
      "Processing Split_09...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 19375 điểm dữ liệu) ---\n",
      "   Quality filter: 128/128 objects pass\n",
      "   | TRAIN | Raw:   19690 -> Final:   19375 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 46725 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   47239 -> Final:   46725 | Saved.\n",
      "\n",
      "Processing Split_10...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 25144 điểm dữ liệu) ---\n",
      "   Quality filter: 144/144 objects pass\n",
      "   | TRAIN | Raw:   25151 -> Final:   25144 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 51005 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   51056 -> Final:   51005 | Saved.\n",
      "\n",
      "Processing Split_11...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 22923 điểm dữ liệu) ---\n",
      "   Quality filter: 146/146 objects pass\n",
      "   | TRAIN | Raw:   22927 -> Final:   22923 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 49711 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   49723 -> Final:   49711 | Saved.\n",
      "\n",
      "Processing Split_12...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 25534 điểm dữ liệu) ---\n",
      "   Quality filter: 155/155 objects pass\n",
      "   | TRAIN | Raw:   25546 -> Final:   25534 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 54486 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   54499 -> Final:   54486 | Saved.\n",
      "\n",
      "Processing Split_13...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 23201 điểm dữ liệu) ---\n",
      "   Quality filter: 143/143 objects pass\n",
      "   | TRAIN | Raw:   23203 -> Final:   23201 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 63638 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   63653 -> Final:   63638 | Saved.\n",
      "\n",
      "Processing Split_14...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 25683 điểm dữ liệu) ---\n",
      "   Quality filter: 154/154 objects pass\n",
      "   | TRAIN | Raw:   25706 -> Final:   25683 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 58600 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   58643 -> Final:   58600 | Saved.\n",
      "\n",
      "Processing Split_15...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 23856 điểm dữ liệu) ---\n",
      "   Quality filter: 158/158 objects pass\n",
      "   | TRAIN | Raw:   23972 -> Final:   23856 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 52746 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   52943 -> Final:   52746 | Saved.\n",
      "\n",
      "Processing Split_16...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 25170 điểm dữ liệu) ---\n",
      "   Quality filter: 155/155 objects pass\n",
      "   | TRAIN | Raw:   25173 -> Final:   25170 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 58179 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   58192 -> Final:   58179 | Saved.\n",
      "\n",
      "Processing Split_17...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 22693 điểm dữ liệu) ---\n",
      "   Quality filter: 153/153 objects pass\n",
      "   | TRAIN | Raw:   22705 -> Final:   22693 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 59461 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   59482 -> Final:   59461 | Saved.\n",
      "\n",
      "Processing Split_18...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 21529 điểm dữ liệu) ---\n",
      "   Quality filter: 152/152 objects pass\n",
      "   | TRAIN | Raw:   21536 -> Final:   21529 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 53873 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   53887 -> Final:   53873 | Saved.\n",
      "\n",
      "Processing Split_19...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 22079 điểm dữ liệu) ---\n",
      "   Quality filter: 147/147 objects pass\n",
      "   | TRAIN | Raw:   22087 -> Final:   22079 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 56339 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   56355 -> Final:   56339 | Saved.\n",
      "\n",
      "Processing Split_20...\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 23509 điểm dữ liệu) ---\n",
      "   Quality filter: 153/153 objects pass\n",
      "   | TRAIN | Raw:   23519 -> Final:   23509 | Saved.\n",
      "--- BẮT ĐẦU GIAI ĐOẠN 2: EXTINCTION CORRECTION ---\n",
      "--- HOÀN THÀNH (Đã sửa 58422 điểm dữ liệu) ---\n",
      "   | TEST  | Raw:   58432 -> Final:   58422 | Saved.\n",
      "\n",
      "===== ALL DONE =====\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== 2. START PROCESSING SPLITS =====\")\n",
    "\n",
    "if not os.path.exists(OUT_ROOT):\n",
    "    os.makedirs(OUT_ROOT)\n",
    "\n",
    "for i in SPLITS:\n",
    "    split_name = f\"Split_{i:02d}\"\n",
    "    split_dir = os.path.join(DATA_ROOT, split_name)\n",
    "\n",
    "    if not os.path.exists(split_dir):\n",
    "        split_name = f\"split_{i:02d}\"\n",
    "        split_dir = os.path.join(DATA_ROOT, split_name)\n",
    "    \n",
    "    if not os.path.exists(split_dir):\n",
    "        continue # Bỏ qua nếu không tìm thấy folder\n",
    "\n",
    "    print(f\"\\nProcessing {split_name}...\")\n",
    "\n",
    "    for mode in [\"train\", \"test\"]:\n",
    "        lc_path = os.path.join(split_dir, f\"{mode}_full_lightcurves.csv\")\n",
    "        \n",
    "        if not os.path.exists(lc_path):\n",
    "            continue\n",
    "\n",
    "        # 1. Clean Basic\n",
    "        lc_step1, n_raw, _ = clean_lightcurve_file(lc_path, is_test_set=(mode == \"test\"))\n",
    "        \n",
    "        if lc_step1.empty:\n",
    "            continue\n",
    "\n",
    "        # 2. Extinction Correction (Chọn Metadata đúng)\n",
    "        current_meta = meta_train_master if mode == \"train\" else meta_test_master\n",
    "        \n",
    "        # Gọi hàm khử bụi\n",
    "        lc_step2 = apply_extinction_correction(lc_step1, current_meta)\n",
    "\n",
    "        if mode == \"train\":\n",
    "            # Áp dụng quality filter cho train set\n",
    "            lc_step2 = apply_quality_filters(lc_step2)\n",
    "\n",
    "        lc_final = lc_step2.copy()\n",
    "\n",
    "        # Lưu file\n",
    "        out_name = f\"split_{i:02d}_{mode}_processed.csv\"\n",
    "        out_path = os.path.join(OUT_ROOT, out_name)\n",
    "        lc_final.to_csv(out_path, index=False)\n",
    "\n",
    "        n_final = len(lc_final)\n",
    "        print(f\"   | {mode.upper():5s} | Raw: {n_raw:7d} -> Final: {n_final:7d} | Saved.\")\n",
    "\n",
    "print(\"\\n===== ALL DONE =====\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
